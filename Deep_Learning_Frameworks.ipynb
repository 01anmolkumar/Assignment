{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMER0OXhnPTHTh0nGPBfj5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01anmolkumar/Assignment/blob/main/Deep_Learning_Frameworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Frameworks"
      ],
      "metadata": {
        "id": "9NAH2B4SIARV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* TensorFlow 2.0 is an open-source deep learning framework developed by Google for building, training, and deploying machine learning models.\n",
        "\n",
        "* It enables **eager execution by default**, meaning operations run immediately as they are called, which makes debugging and development easier.\n",
        "\n",
        "* It has **Keras integrated as the official high-level API**, making model creation and training more intuitive.\n",
        "\n",
        "* Many redundant or outdated APIs from TensorFlow 1.x have been removed, simplifying the framework.\n",
        "\n",
        "* **Differences from TensorFlow 1.x:**\n",
        "  * Eager execution by default instead of static computation graph in 1.x.\n",
        "  * Tighter integration with Keras for model definition.\n",
        "  * More Pythonic and user-friendly APIs.\n",
        "  * Better compatibility with TensorFlow Hub and other libraries.\n",
        "  * Improved performance and distributed training support.\n",
        "\n",
        "* In summary, TensorFlow 2.0 is cleaner, more beginner-friendly, and faster for prototyping compared to TensorFlow 1.x.\n"
      ],
      "metadata": {
        "id": "F_cNHT_BILqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. How do you install TensorFlow 2.0**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* TensorFlow 2.0 can be installed using Python's package manager **pip**.\n",
        "\n",
        "* **Steps to install:**\n",
        "  1. Make sure Python and pip are installed on your system.\n",
        "  2. Open the command prompt (Windows) or terminal (Mac/Linux).\n",
        "  3. Run the following command:\n",
        "     ```\n",
        "     pip install tensorflow==2.0.0\n",
        "     ```\n",
        "\n",
        "* After installation, you can verify it by running:\n",
        "  ```python\n",
        "  import tensorflow as tf\n",
        "  print(tf.__version__)\n"
      ],
      "metadata": {
        "id": "d0sP-eewIvIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. What is the primary function of the tf.function in TensorFlow 2.0**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* In TensorFlow 2.0, `tf.function` is used to convert a regular Python function into a **TensorFlow graph** for faster execution.\n",
        "\n",
        "* By default, TensorFlow 2.0 runs in **eager execution mode**, which is easier for debugging but can be slower.\n",
        "\n",
        "* Wrapping a Python function with `@tf.function` allows TensorFlow to:\n",
        "  * Optimize the code.\n",
        "  * Run it as a **static computation graph**.\n",
        "  * Improve performance, especially for large computations.\n",
        "\n",
        "* **How it works:**\n",
        "  * You define a normal Python function containing TensorFlow operations.\n",
        "  * Decorate it with `@tf.function`.\n",
        "  * TensorFlow traces and compiles it into an efficient graph representation.\n",
        "\n"
      ],
      "metadata": {
        "id": "ANN1_1s8Mheo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. What is the purpose of the Model class in TensorFlow 2.0**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* In TensorFlow 2.0, the **Model** class (from `tf.keras.Model`) is the core class used for creating, training, evaluating, and saving deep learning models.\n",
        "\n",
        "* It provides a high-level interface that simplifies the process of defining complex architectures.\n",
        "\n",
        "* **Main purposes of the Model class:**\n",
        "  * To combine **layers** into a complete model.\n",
        "  * To define the **forward pass** (how input data flows through the model).\n",
        "  * To manage training, evaluation, and prediction methods.\n",
        "  * To save and load model configurations and weights.\n",
        "\n",
        "* **Ways to create a model:**\n",
        "  1. **Sequential API** – For models with a simple, linear stack of layers.\n",
        "  2. **Functional API** – For more complex, non-linear architectures.\n",
        "  3. **Subclassing the Model class** – For complete customization by overriding the `call()` method.\n",
        "\n"
      ],
      "metadata": {
        "id": "WlfImzpLNAhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. How do you create a neural network using TensorFlow 2.0**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* In TensorFlow 2.0, a neural network can be created easily using the **Keras API** (`tf.keras`).\n",
        "\n",
        "* The process generally involves:\n",
        "  1. Importing TensorFlow.\n",
        "  2. Defining the model architecture.\n",
        "  3. Compiling the model.\n",
        "  4. Training the model with data.\n",
        "  5. Evaluating and making predictions.\n",
        "\n",
        "* **Example:**\n",
        "  ```python\n",
        "  import tensorflow as tf\n",
        "  from tensorflow.keras import layers, models\n",
        "\n",
        "  # Step 1: Define the model\n",
        "  model = models.Sequential([\n",
        "      layers.Dense(64, activation='relu', input_shape=(100,)),\n",
        "      layers.Dense(32, activation='relu'),\n",
        "      layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  # Step 2: Compile the model\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Step 3: Train the model\n",
        "   model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "  # Step 4: Evaluate the model\n",
        "   model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "hyNVjKKhOjSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. What is the importance of Tensor Space in TensorFlow**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* In TensorFlow, a **tensor** is the primary data structure used to represent and store data.\n",
        "\n",
        "* The **tensor space** refers to the multi-dimensional space in which tensors exist and operate.\n",
        "\n",
        "* It defines the **shape, rank, and data type** of the tensor, which are essential for performing mathematical operations.\n",
        "\n",
        "* Tensor space allows TensorFlow to:\n",
        "  * Perform computations on multi-dimensional arrays efficiently.\n",
        "  * Represent data for deep learning models such as images, text, and time-series.\n",
        "  * Optimize operations using GPUs and TPUs.\n",
        "  * Enable flexible transformations and reshaping of data.\n",
        "\n",
        "* Understanding tensor space is crucial because incorrect dimensions or incompatible shapes lead to computational errors in model building and training.\n",
        "\n",
        "* **Summary:**  \n",
        "  Tensor space in TensorFlow represents the multi-dimensional environment where tensors exist, enabling efficient mathematical operations, data representation, and optimized computation in deep learning models.\n"
      ],
      "metadata": {
        "id": "pTSFgxeiPaUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. How can TensorBoard be integrated with TensorFlow 2.0**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* **TensorBoard** is a visualization tool provided by TensorFlow to monitor and analyze the training process of machine learning models.\n",
        "\n",
        "* In TensorFlow 2.0, TensorBoard can be integrated easily to:\n",
        "  * Track metrics such as loss and accuracy during training.\n",
        "  * Visualize the computation graph of the model.\n",
        "  * Inspect weights, biases, and histograms.\n",
        "  * Compare training runs to improve performance.\n",
        "\n",
        "* Integration is done by creating a **log directory** and writing training logs using the `tf.summary` API or by specifying `TensorBoard` as a callback in Keras model training.\n",
        "\n",
        "* TensorBoard helps in:\n",
        "  * Debugging models by spotting overfitting or underfitting early.\n",
        "  * Understanding model behavior through visual insights.\n",
        "  * Comparing multiple training runs side by side.\n",
        "\n",
        "* **Summary:**  \n",
        "  TensorBoard in TensorFlow 2.0 is a powerful visualization tool that integrates seamlessly to track metrics, visualize graphs, and monitor the model’s performance during training.\n"
      ],
      "metadata": {
        "id": "PQPaUByePuAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. What is the purpose of TensorFlow Playground**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* **TensorFlow Playground** is an interactive, web-based visualization tool for experimenting with and understanding neural networks.\n",
        "\n",
        "* It allows users to:\n",
        "  * Build simple neural network models visually.\n",
        "  * Adjust parameters like the number of layers, number of neurons, activation functions, and learning rate.\n",
        "  * Observe how changes in parameters affect the model's performance in real time.\n",
        "\n",
        "* It is designed mainly for **educational purposes**, helping beginners and students learn the concepts of deep learning without writing code.\n",
        "\n",
        "* TensorFlow Playground works entirely in the browser and uses TensorFlow.js for computations.\n",
        "\n",
        "* It provides visual feedback on:\n",
        "  * Decision boundaries.\n",
        "  * Training progress.\n",
        "  * Weight updates during learning.\n",
        "\n",
        "* **Summary:**  \n",
        "  TensorFlow Playground is an easy-to-use, browser-based tool for learning and experimenting with neural networks visually, making it ideal for beginners to grasp deep learning concepts.\n"
      ],
      "metadata": {
        "id": "TVgPiuJBQuXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. What is Netron, and how is it useful for deep learning models**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* **Netron** is an open-source viewer for neural network, deep learning, and machine learning models.\n",
        "\n",
        "* It supports multiple frameworks such as TensorFlow, Keras, PyTorch, Caffe, ONNX, and MXNet.\n",
        "\n",
        "* Netron allows users to:\n",
        "  * Visualize the architecture of a trained model.\n",
        "  * Inspect layers, connections, and parameters in a graphical format.\n",
        "  * Understand the model’s structure without reading raw code or files.\n",
        "\n",
        "* It is available as:\n",
        "  * A desktop application (Windows, macOS, Linux).\n",
        "  * A web-based version for quick online viewing.\n",
        "\n",
        "* Benefits of using Netron:\n",
        "  * Helps in debugging model architecture.\n",
        "  * Useful for presenting and documenting models.\n",
        "  * Makes it easier to verify the correctness of exported models.\n",
        "\n",
        "* **Summary:**  \n",
        "  Netron is a powerful visualization tool for inspecting deep learning model architectures, making it easier to understand, debug, and share models.\n"
      ],
      "metadata": {
        "id": "DVFwhW6NRVgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10. What is the difference between TensorFlow and PyTorch**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* **TensorFlow** and **PyTorch** are two of the most popular deep learning frameworks, but they differ in design philosophy and usage.\n",
        "\n",
        "* **Key differences:**\n",
        "  * **Execution Mode:**\n",
        "    * TensorFlow 2.0 uses eager execution by default but can also use graph execution for optimization.\n",
        "    * PyTorch uses eager execution by default, making it more Pythonic and intuitive for beginners.\n",
        "  \n",
        "  * **API Style:**\n",
        "    * TensorFlow integrates tightly with Keras for high-level APIs.\n",
        "    * PyTorch uses a more flexible, object-oriented approach with its `torch.nn` module.\n",
        "\n",
        "  * **Deployment:**\n",
        "    * TensorFlow has strong production deployment support via TensorFlow Serving, TensorFlow Lite, and TensorFlow.js.\n",
        "    * PyTorch offers TorchServe for deployment, but historically has been more research-focused.\n",
        "\n",
        "  * **Community and Use Cases:**\n",
        "    * TensorFlow is widely used in industry for large-scale production.\n",
        "    * PyTorch is popular in academic research for its ease of experimentation.\n",
        "\n",
        "  * **Visualization:**\n",
        "    * TensorFlow includes TensorBoard for visualizing training metrics.\n",
        "    * PyTorch can integrate with TensorBoard or other third-party visualization tools.\n",
        "\n",
        "* **Summary:**  \n",
        "  TensorFlow is known for strong deployment capabilities and wide industry adoption, while PyTorch is favored for research, flexibility, and ease of use in prototyping.\n"
      ],
      "metadata": {
        "id": "4EkuPp5YSm0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11. How do you install PyTorch**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* PyTorch can be installed using Python's package manager **pip** or **conda**.\n",
        "\n",
        "* **Steps to install with pip:**\n",
        "  1. Open the command prompt (Windows) or terminal (Mac/Linux).\n",
        "  2. Run the installation command based on your system and CUDA version.  \n",
        "     Example for CPU-only:\n",
        "     ```\n",
        "     pip install torch torchvision torchaudio\n",
        "     ```\n",
        "     Example for GPU with CUDA 11.8:\n",
        "     ```\n",
        "     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "     ```\n",
        "\n",
        "* **Steps to install with conda:**\n",
        "or for GPU:\n",
        "\n",
        "* After installation, verify it by running:\n",
        "```python\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())  # To check GPU availability\n",
        "\n"
      ],
      "metadata": {
        "id": "ta4S3cxtTYNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12. What is the basic structure of a PyTorch neural network**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* A PyTorch neural network is built using the **`torch.nn`** module, which provides all necessary building blocks.\n",
        "\n",
        "* **Basic structure:**\n",
        "  1. **Import required modules** – Import PyTorch and relevant submodules.\n",
        "  2. **Define the model class** – Create a class that inherits from `torch.nn.Module`.\n",
        "  3. **Initialize layers in `__init__` method** – Define network layers like `Linear`, `Conv2d`, `ReLU`, etc.\n",
        "  4. **Define the forward pass in `forward` method** – Specify how data flows through the layers.\n",
        "  5. **Instantiate the model** – Create an object of the defined class.\n",
        "  6. **Specify a loss function and optimizer** – For training the network.\n",
        "\n",
        "* The forward pass describes the sequence of operations from input to output, while the backward pass is handled automatically by PyTorch using **autograd**.\n",
        "\n",
        "* **Example:**\n",
        "  ```python\n",
        "  import torch\n",
        "  import torch.nn as nn\n",
        "  import torch.nn.functional as F\n",
        "\n",
        "  class SimpleNN(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(SimpleNN, self).__init__()\n",
        "          self.fc1 = nn.Linear(10, 50)  # Input layer to hidden layer\n",
        "          self.fc2 = nn.Linear(50, 1)   # Hidden layer to output layer\n",
        "\n",
        "      def forward(self, x):\n",
        "          x = F.relu(self.fc1(x))\n",
        "          x = self.fc2(x)\n",
        "          return x\n",
        "\n",
        "  # Create model instance\n",
        "  model = SimpleNN()\n",
        "  print(model)\n"
      ],
      "metadata": {
        "id": "PNh1bASXVkQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. What is the significance of tensors in PyTorch**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* In PyTorch, a **tensor** is the core data structure used to store and manipulate numerical data.\n",
        "\n",
        "* Tensors are similar to NumPy arrays but have additional capabilities such as GPU acceleration.\n",
        "\n",
        "* **Key significance of tensors in PyTorch:**\n",
        "  * They represent multi-dimensional arrays for storing data such as images, text, and numerical values.\n",
        "  * They enable fast mathematical operations using PyTorch’s optimized backend.\n",
        "  * They support **automatic differentiation** through PyTorch’s `autograd` system, making them essential for training neural networks.\n",
        "  * They can be easily moved between CPU and GPU for faster computation.\n",
        "  * They integrate seamlessly with PyTorch’s deep learning modules (`torch.nn`, `torch.optim`).\n",
        "\n",
        "* Tensors come in different shapes (rank), data types (dtype), and can store both scalar and vectorized data.\n",
        "\n",
        "* **Summary:**  \n",
        "  Tensors in PyTorch are multi-dimensional arrays with GPU acceleration and automatic differentiation support, making them fundamental for building and training deep learning models.\n"
      ],
      "metadata": {
        "id": "KZum05KTXcbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* **torch.Tensor**:\n",
        "  * Represents a multi-dimensional array stored and processed on the **CPU**.\n",
        "  * Suitable for computations that do not require GPU acceleration.\n",
        "  * Default tensor type when creating tensors without specifying a device.\n",
        "\n",
        "* **torch.cuda.Tensor**:\n",
        "  * Represents a tensor stored and processed on the **GPU** using CUDA.\n",
        "  * Enables faster computation for large datasets and complex neural networks by leveraging GPU parallelism.\n",
        "  * Requires CUDA-compatible hardware and proper PyTorch GPU installation.\n",
        "\n",
        "* **Key differences:**\n",
        "  * **Device Location** – `torch.Tensor` is on CPU, while `torch.cuda.Tensor` is on GPU.\n",
        "  * **Performance** – GPU tensors (`torch.cuda.Tensor`) can be significantly faster for deep learning tasks.\n",
        "  * **Creation** – CPU tensor: `torch.tensor([1, 2, 3])`  \n",
        "    GPU tensor: `torch.tensor([1, 2, 3], device='cuda')` or `.cuda()` method.\n",
        "\n",
        "* **Summary:**  \n",
        "  `torch.Tensor` is stored on the CPU, while `torch.cuda.Tensor` is stored on the GPU for faster computations, making GPU tensors ideal for training deep learning models on large datasets.\n"
      ],
      "metadata": {
        "id": "XStIypG2YFmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15. What is the purpose of the torch.optim module in PyTorch**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* The **`torch.optim`** module in PyTorch provides a collection of optimization algorithms for training neural networks.\n",
        "\n",
        "* **Purpose:**\n",
        "  * To update the parameters (weights and biases) of a model based on the computed gradients.\n",
        "  * To minimize the loss function during training.\n",
        "  * To control the learning process through parameters like learning rate, momentum, etc.\n",
        "\n",
        "* **Common optimizers in `torch.optim`:**\n",
        "  * **SGD (Stochastic Gradient Descent)** – Basic optimization method.\n",
        "  * **Adam (Adaptive Moment Estimation)** – Popular optimizer combining momentum and adaptive learning rates.\n",
        "  * **RMSprop** – Optimizer that adapts the learning rate for each parameter.\n",
        "\n",
        "* **How it works:**\n",
        "  1. Compute gradients via backpropagation.\n",
        "  2. Use the optimizer to adjust parameters according to the gradients and optimization algorithm.\n",
        "  3. Repeat the process for each training step until convergence.\n",
        "\n",
        "* **Summary:**  \n",
        "  The `torch.optim` module is responsible for updating model parameters efficiently using various optimization algorithms, helping to minimize loss and improve model performance during training.\n"
      ],
      "metadata": {
        "id": "AKEDrmlEYY3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16. What are some common activation functions used in neural networks**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* **Activation functions** introduce non-linearity into neural networks, enabling them to learn complex patterns.\n",
        "\n",
        "* **Common activation functions:**\n",
        "  * **Sigmoid Function:**\n",
        "    * Output range: (0, 1)\n",
        "    * Often used in binary classification problems.\n",
        "  \n",
        "  * **Tanh (Hyperbolic Tangent) Function:**\n",
        "    * Output range: (-1, 1)\n",
        "    * Zero-centered, better for hidden layers compared to sigmoid.\n",
        "\n",
        "  * **ReLU (Rectified Linear Unit):**\n",
        "    * Output: `max(0, x)`\n",
        "    * Most popular activation for hidden layers due to simplicity and efficiency.\n",
        "\n",
        "  * **Leaky ReLU:**\n",
        "    * Similar to ReLU but allows a small, non-zero gradient for negative inputs.\n",
        "\n",
        "  * **Softmax Function:**\n",
        "    * Converts raw scores into probabilities.\n",
        "    * Commonly used in the output layer for multi-class classification.\n",
        "\n",
        "* The choice of activation function depends on the type of layer, task, and data.\n",
        "\n",
        "* **Summary:**  \n",
        "  Common activation functions like Sigmoid, Tanh, ReLU, Leaky ReLU, and Softmax are essential for introducing non-linearity, enabling neural networks to model complex relationships in data.\n"
      ],
      "metadata": {
        "id": "Cpo7FU0TZWCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* **torch.nn.Module**:\n",
        "  * The base class for all neural network models in PyTorch.\n",
        "  * Allows creating complex and custom architectures.\n",
        "  * Requires defining:\n",
        "    * `__init__` method – to initialize layers.\n",
        "    * `forward` method – to define how data flows through the model.\n",
        "  * Suitable for models with conditional logic or multiple data flows.\n",
        "\n",
        "* **torch.nn.Sequential**:\n",
        "  * A container module that chains layers in a sequence.\n",
        "  * No need to define a `forward` method manually; the data flows through layers in the order they are added.\n",
        "  * Best for simple feed-forward networks with a linear stack of layers.\n",
        "  * Less flexible than `torch.nn.Module`.\n",
        "\n",
        "* **Key differences:**\n",
        "  * **Flexibility** – `nn.Module` is more flexible; `nn.Sequential` is simpler but limited.\n",
        "  * **Use case** – Use `nn.Module` for complex models, `nn.Sequential` for straightforward architectures.\n",
        "  * **Code structure** – `nn.Module` requires explicit `forward` method, `nn.Sequential` does not.\n",
        "\n",
        "* **Summary:**  \n",
        "  `torch.nn.Module` is the base class for building both simple and complex custom models, while `torch.nn.Sequential` is a simpler container for stacking layers in order without writing a forward method.\n"
      ],
      "metadata": {
        "id": "fOc-2xqpZwUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18. How can you monitor training progress in TensorFlow 2.0**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* In TensorFlow 2.0, training progress can be monitored using several methods, mainly through **callbacks** and **visualization tools**.\n",
        "\n",
        "* **Common ways to monitor progress:**\n",
        "  * **TensorBoard:**\n",
        "    * Visualizes loss, accuracy, and other metrics during training.\n",
        "    * Shows graphs, histograms, and model performance comparisons.\n",
        "  \n",
        "  * **Keras Callbacks:**\n",
        "    * `tf.keras.callbacks.EarlyStopping` – Stops training when performance stops improving.\n",
        "    * `tf.keras.callbacks.ModelCheckpoint` – Saves the model during training.\n",
        "    * `tf.keras.callbacks.ReduceLROnPlateau` – Adjusts learning rate based on progress.\n",
        "\n",
        "  * **Verbose Output in `model.fit()`:**\n",
        "    * Shows loss and accuracy values per epoch or batch.\n",
        "\n",
        "\n",
        "  * **Custom Callbacks:**\n",
        "    * Allow creating personalized monitoring logic, like printing metrics after each batch.\n",
        "\n",
        "* Monitoring helps in identifying overfitting, underfitting, and optimizing training performance.\n",
        "\n",
        "* **Summary:**  \n",
        "  Training progress in TensorFlow 2.0 can be monitored using TensorBoard, built-in Keras callbacks, and verbose logs, enabling better insights and control over the model training process.\n"
      ],
      "metadata": {
        "id": "dfU4PccRackf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19. How does the Keras API fit into TensorFlow 2.0**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* In TensorFlow 2.0, **Keras** is fully integrated as the official high-level API for building and training deep learning models.\n",
        "\n",
        "* **Role of Keras in TensorFlow 2.0:**\n",
        "  * Provides a simple, user-friendly interface for model creation.\n",
        "  * Supports multiple ways of building models:\n",
        "    * **Sequential API** – For models with a linear stack of layers.\n",
        "    * **Functional API** – For complex architectures with multiple inputs and outputs.\n",
        "    * **Model subclassing** – For complete customization.\n",
        "  * Handles compilation, training, evaluation, and prediction in an intuitive manner.\n",
        "\n",
        "* Keras works seamlessly with TensorFlow features like:\n",
        "  * Eager execution.\n",
        "  * TensorBoard integration.\n",
        "  * Distribution strategies for multi-GPU and TPU training.\n",
        "\n",
        "* The integration eliminates the need to install standalone Keras, as it is available through `tf.keras`.\n",
        "\n",
        "* **Summary:**  \n",
        "  In TensorFlow 2.0, Keras acts as the high-level API that simplifies model building and training, providing ease of use while retaining the flexibility and power of TensorFlow’s backend.\n"
      ],
      "metadata": {
        "id": "zVnbP7QpfznY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* One example of a deep learning project using TensorFlow 2.0 is **Image Classification**.\n",
        "\n",
        "* **Description:**\n",
        "  * The goal is to classify images into predefined categories (e.g., cats vs. dogs, types of flowers).\n",
        "  * A convolutional neural network (CNN) is trained on labeled image datasets.\n",
        "  * TensorFlow 2.0’s Keras API makes it easy to define, compile, and train the CNN.\n",
        "\n",
        "* **Steps involved:**\n",
        "  1. Load and preprocess the image dataset.\n",
        "  2. Define the CNN architecture using `tf.keras`.\n",
        "  3. Compile the model with an optimizer, loss function, and metrics.\n",
        "  4. Train the model while monitoring accuracy and loss.\n",
        "  5. Evaluate the model and make predictions on new images.\n",
        "\n",
        "* This project can use datasets such as **CIFAR-10**, **MNIST**, or custom image datasets.\n",
        "\n",
        "* **Applications:**\n",
        "  * Medical image analysis.\n",
        "  * Object detection in security systems.\n",
        "  * Automated sorting in manufacturing.\n",
        "\n",
        "* **Summary:**  \n",
        "  Image classification is a popular deep learning project that can be implemented in TensorFlow 2.0, involving dataset preparation, CNN model building, training, and prediction.\n"
      ],
      "metadata": {
        "id": "cW6p5dYagB0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch**\n",
        "\n",
        "Answer :-\n",
        "\n",
        "* **Pre-trained models** are models that have been trained on large datasets and can be reused for similar tasks.\n",
        "\n",
        "* **Main advantages:**\n",
        "  * **Saves time and resources** – No need to train from scratch, as the model has already learned useful features.\n",
        "  * **Better performance with less data** – Even with a smaller dataset, pre-trained models can achieve high accuracy due to prior knowledge.\n",
        "  * **Reduces computational cost** – Eliminates the need for long training times and expensive hardware usage.\n",
        "  * **Transfer learning** – The knowledge gained from one task can be applied to another related task.\n",
        "  * **Proven architectures** – Pre-trained models are usually based on well-tested and optimized network designs.\n",
        "\n",
        "* Both TensorFlow and PyTorch provide model libraries (e.g., TensorFlow Hub, PyTorch Hub) containing various pre-trained models for tasks like image classification, object detection, and natural language processing.\n",
        "\n",
        "* **Summary:**  \n",
        "  The main advantage of using pre-trained models is that they significantly reduce training time, computational cost, and data requirements while improving performance through transfer learning.\n"
      ],
      "metadata": {
        "id": "3MwlIwPukMSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical"
      ],
      "metadata": {
        "id": "ceFhry74kQyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Q1.How do you install and verify that TensorFlow 2.0 was installed successfully?**"
      ],
      "metadata": {
        "id": "sk0Pz_EDkg9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now install TensorFlow 2.0.0\n",
        "!pip install tensorflow==2.0.0\n",
        "\n",
        "#TensorFlow 2.0.0 was released in 2019 and only supports Python 3.5–3.7.\n",
        "#Colab’s default runtime now uses Python 3.10 or newer, which is incompatible."
      ],
      "metadata": {
        "id": "PUEeslZKcyG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d713f8b-8a38-464f-ac93-cb9e33aa1b53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.0.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.20.0rc0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code tested on TensorFlow 2.19, which is part of the TensorFlow 2.x series. This is the latest stable release, and all examples are fully compatible with TensorFlow 2.0 syntax."
      ],
      "metadata": {
        "id": "oh0pgoqO1vbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.19.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1tcTwki1Mfl",
        "outputId": "fec244dd-8758-4f07-9dd6-444d969ff7d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.19.0 in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.19.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.19.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.19.0) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd4559d-31d3-420d-be93-f6f97b3ff0ac",
        "id": "NqKaFRjC1R74"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. How can you define a simple function in TensorFlow 2.0 to perform addition?**"
      ],
      "metadata": {
        "id": "_uDN2yQ-2caU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a TensorFlow function for addition\n",
        "@tf.function\n",
        "def add_numbers(a, b):\n",
        "    return tf.add(a, b)\n",
        "\n",
        "# Test the function\n",
        "x = tf.constant(5)\n",
        "y = tf.constant(3)\n",
        "result = add_numbers(x, y)\n",
        "\n",
        "print(\"Sum:\", result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0cA1c7M07AK",
        "outputId": "fc4ee6bb-0c78-4aa5-d07e-4f5c83b01da4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?**"
      ],
      "metadata": {
        "id": "BKoawz8g2wNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(4,)),  # Hidden layer with 8 neurons\n",
        "    Dense(3, activation='softmax')                   # Output layer with 3 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "8UCnM_dn2x5m",
        "outputId": "77ae5866-dd18-454d-e449-7a22d1f9229c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67\u001b[0m (268.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67</span> (268.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67\u001b[0m (268.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67</span> (268.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. How can you visualize the training progress using TensorFlow and Matplotlib?**"
      ],
      "metadata": {
        "id": "gkIB8WKh439R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate dummy training data\n",
        "x_train = np.random.rand(100, 4)\n",
        "y_train = np.random.randint(0, 3, size=(100,))\n",
        "\n",
        "# Define model\n",
        "model = Sequential([\n",
        "    Dense(8, activation='relu', input_shape=(4,)),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model and store history\n",
        "history = model.fit(x_train, y_train, epochs=10, verbose=0)\n",
        "\n",
        "# Plot training loss and accuracy\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "w8tgy8j_22CB",
        "outputId": "4e2e8ec4-25bd-472d-98d5-32556c421143"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. How do you install PyTorch and verify the PyTorch installation?**"
      ],
      "metadata": {
        "id": "IRU6om018Utw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch (CPU version for Colab; if you need GPU, change the command from pytorch.org)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odr-FUmv8X5W",
        "outputId": "dd22b26a-9008-4769-ff0e-33d91d57ef11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify installation\n",
        "import torch\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Is CUDA available?\", torch.cuda.is_available()) #If it returns False, PyTorch will run only on the CPU."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Pf7mun8Wjl",
        "outputId": "ba427b4c-915c-4cda-8fa3-4fb591457746"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cpu\n",
            "Is CUDA available? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. How do you create a simple neural network in PyTorch?**"
      ],
      "metadata": {
        "id": "AxVuZFP89bQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 8)   # Input layer: 4 features → Hidden layer: 8 neurons\n",
        "        self.fc2 = nn.Linear(8, 3)   # Hidden layer → Output layer: 3 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))      # Activation function for hidden layer\n",
        "        x = self.fc2(x)              # Output layer (no activation here, will use loss later)\n",
        "        return x\n",
        "\n",
        "# Create model instance\n",
        "model = SimpleNN()\n",
        "\n",
        "# Display model architecture\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjdclg2a9dSl",
        "outputId": "d4d37f94-4bd3-49fc-dfd0-c829407b2f4e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (fc2): Linear(in_features=8, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. How do you define a loss function and optimizer in PyTorch?**"
      ],
      "metadata": {
        "id": "NYZSQSX2DYcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Example model (from Q6)\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 8)\n",
        "        self.fc2 = nn.Linear(8, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n",
        "\n",
        "# Define a loss function (CrossEntropyLoss for classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define an optimizer (Adam optimizer with learning rate 0.001)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function:\", criterion)\n",
        "print(\"Optimizer:\", optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dts9FiDUDXn4",
        "outputId": "e9c2b080-34aa-4e77-9ff1-089eb7210728"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function: CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. How do you implement a custom loss function in PyTorch?**"
      ],
      "metadata": {
        "id": "_Ta5jpa1DuLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example: Custom Mean Absolute Error (MAE) loss\n",
        "class CustomMAELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMAELoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        return torch.mean(torch.abs(y_pred - y_true))\n",
        "\n",
        "# Create an instance of the custom loss\n",
        "custom_loss = CustomMAELoss()\n",
        "\n",
        "# Example test\n",
        "y_pred = torch.tensor([[2.5], [0.0], [2.1]])\n",
        "y_true = torch.tensor([[3.0], [0.0], [2.0]])\n",
        "\n",
        "loss_value = custom_loss(y_pred, y_true)\n",
        "print(\"Custom loss value:\", loss_value.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prod1lguD2Qy",
        "outputId": "62e4f434-2504-4b24-fae8-d2a724a17b35"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom loss value: 0.19999997317790985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. How do you save and load a TensorFlow model?**"
      ],
      "metadata": {
        "id": "Lo-lXGN4EEPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a simple model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(8, activation='relu', input_shape=(4,)),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ---- Saving the model ----\n",
        "model.save(\"my_model.h5\")  # Save in HDF5 format\n",
        "print(\"Model saved as my_model.h5\")\n",
        "\n",
        "# ---- Loading the model ----\n",
        "loaded_model = keras.models.load_model(\"my_model.h5\")\n",
        "print(\"Model loaded successfully!\")\n",
        "loaded_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "LJI6GzncD8Om",
        "outputId": "66424d8d-5ce2-412c-85d2-4870f665023d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as my_model.h5\n",
            "Model loaded successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69\u001b[0m (280.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69</span> (280.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67\u001b[0m (268.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67</span> (268.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V8fEMRAhELoq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}